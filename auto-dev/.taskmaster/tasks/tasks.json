{
  "master": {
    "tasks": [
      {
        "id": "22",
        "title": "Create apply-rules Skill structure and rule loading mechanism",
        "description": "Implement the foundational apply-rules Skill that loads and parses project rules from .autodev/rules.md file. This skill is responsible for reading stored business rules and preparing them for matching against current tasks.",
        "details": "Create skills/apply-rules/SKILL.md with the following implementation:\n1. Implement rule file loader that reads .autodev/rules.md\n2. Parse markdown format rules into structured data (rule text, context, category)\n3. Handle missing or empty rules.md gracefully (return empty list)\n4. Store parsed rules in memory for matching phase\n5. Implement error handling for file read failures\n\nPseudo-code:\n```\nfunction loadRules():\n  try:\n    content = readFile('.autodev/rules.md')\n    rules = parseMarkdown(content)\n    return rules\n  catch FileNotFound:\n    return []\n  catch ParseError:\n    log error and return []\n```\n\nImplementation should follow Node.js/TypeScript best practices with proper error handling and logging.",
        "testStrategy": "Unit tests should verify: (1) Correct parsing of rules.md with multiple rules, (2) Empty list returned when rules.md doesn't exist, (3) Proper error handling for malformed markdown, (4) Rules are stored with metadata (text, line number, category)",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:32:38.276Z"
      },
      {
        "id": "23",
        "title": "Implement rule matching algorithm based on task description",
        "description": "Develop the rule matching logic that analyzes current task descriptions and identifies relevant historical rules. Rules should be matched using semantic similarity and ranked by relevance score.",
        "details": "Implement matching algorithm in apply-rules Skill:\n1. Create similarity scoring function (use keyword matching, semantic analysis, or embedding-based approach)\n2. Compare current task description against all loaded rules\n3. Filter rules with relevance score above threshold (e.g., 0.5)\n4. Sort matched rules by relevance score (descending)\n5. Return top N rules (configurable, default 5)\n\nPseudo-code:\n```\nfunction matchRules(taskDescription, rules):\n  matches = []\n  for each rule in rules:\n    score = calculateSimilarity(taskDescription, rule.text)\n    if score > THRESHOLD:\n      matches.push({rule, score})\n  return sortByScore(matches, descending)\n```\n\nConsider using string similarity libraries or simple keyword overlap for MVP. Can be enhanced with embeddings later.",
        "testStrategy": "Test with various task descriptions: (1) Task with exact keyword match should rank high, (2) Task with partial match should be included, (3) Unrelated task should return empty or low-scoring results, (4) Sorting order verified by relevance scores, (5) Edge case: empty task description",
        "priority": "high",
        "dependencies": [
          "22"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:32:47.499Z"
      },
      {
        "id": "24",
        "title": "Integrate apply-rules into execute-loop Skill",
        "description": "Update the execute-loop Skill to call apply-rules at the beginning of each iteration, before task execution. This ensures rules are applied to every task automatically.",
        "details": "Modify execute-loop/SKILL.md to add rule application step:\n1. After getting current task from TaskMaster (step 1)\n2. Before TDD implementation (step 4)\n3. Call apply-rules skill with current task description\n4. Store matched rules in execution context\n5. Pass matched rules to execute-prompt template\n\nUpdate execute-loop flow:\n```\n1. Get current task (TaskMaster.next_task)\n2. Apply rules (apply-rules skill) ← NEW\n3. Build execution context (execute-prompt template) ← NEW\n4. TDD implementation\n5. Verify and mark complete\n```\n\nEnsure matched rules are available in the context for template variable substitution.",
        "testStrategy": "Integration test: (1) Execute-loop calls apply-rules for each iteration, (2) Matched rules are passed to template, (3) Rules appear in final prompt sent to Claude, (4) Loop continues normally with or without matched rules",
        "priority": "high",
        "dependencies": [
          "23"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:33:27.193Z"
      },
      {
        "id": "25",
        "title": "Create execute-prompt.md template with variable placeholders",
        "description": "Implement the execute-prompt.md template that defines the execution context structure with all required variable placeholders for task information, project facts, and matched rules.",
        "details": "Create templates/execute-prompt.md with the following structure:\n1. Header explaining Auto-Dev execution context\n2. Current Task section with {{task_id}}, {{task_description}}, {{dependencies}}\n3. Project Context section with {{project_facts}}\n4. Applicable Rules section with {{matched_rules}}\n5. Execution Requirements section (TDD, verification, debugging)\n6. Completion Conditions section\n\nTemplate content:\n```\n你正在执行 Auto-Dev 自动化开发任务。\n\n## 当前任务\n- 任务ID: {{task_id}}\n- 任务描述: {{task_description}}\n- 依赖任务: {{dependencies}}\n\n## 项目上下文\n{{project_facts}}\n\n## 适用规则\n{{matched_rules}}\n\n## 执行要求\n1. 遵循 TDD 流程\n2. 每次修改后运行验证\n3. 必须有验证证据\n4. 遇到问题调用 systematic-debugging\n\n## 完成条件\n当任务验证通过后，调用 TaskMaster set_task_status(done)\n```\n\nEnsure template is in markdown format and uses consistent placeholder syntax {{variable_name}}.",
        "testStrategy": "Validation tests: (1) Template file exists and is readable, (2) All required placeholders are present, (3) Template structure is valid markdown, (4) No syntax errors in placeholder names",
        "priority": "high",
        "dependencies": [
          "24"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:33:52.870Z"
      },
      {
        "id": "26",
        "title": "Implement template variable substitution engine",
        "description": "Create a template engine that replaces all {{variable}} placeholders with actual values from task data, project facts, and matched rules. Handle missing or null values gracefully.",
        "details": "Implement template substitution in execute-loop or a dedicated template utility:\n1. Create function that takes template string and variable map\n2. Find all {{variable_name}} patterns using regex\n3. Replace with corresponding values from map\n4. Handle missing variables (use empty string or placeholder text)\n5. Handle special characters and escaping\n6. Return fully substituted prompt string\n\nPseudo-code:\n```\nfunction substituteTemplate(template, variables):\n  result = template\n  pattern = /\\{\\{([^}]+)\\}\\}/g\n  result = result.replace(pattern, (match, varName) => {\n    return variables[varName] || ''\n  })\n  return result\n```\n\nVariable map should include:\n- task_id, task_description, dependencies (from TaskMaster)\n- project_facts (from .autodev/project-facts.json)\n- matched_rules (from apply-rules skill output)",
        "testStrategy": "Unit tests: (1) Single variable substitution, (2) Multiple variables in template, (3) Missing variable returns empty string, (4) Special characters handled correctly, (5) Nested or malformed placeholders handled gracefully, (6) Complex values (arrays, objects) formatted appropriately",
        "priority": "high",
        "dependencies": [
          "25"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:33:52.871Z"
      },
      {
        "id": "27",
        "title": "Implement /auto-dev:status command",
        "description": "Create the status command that displays current execution state including branch, task progress, current task details, iteration count, and recent validation results. This is a read-only operation.",
        "details": "Create commands/status.md with implementation:\n1. Read current git branch using `git rev-parse --abbrev-ref HEAD`\n2. Call TaskMaster get_tasks to retrieve all tasks and their statuses\n3. Calculate progress: count completed tasks / total tasks\n4. Get current task from TaskMaster next_task\n5. Read iteration count from execution state file (if exists)\n6. Read latest validation results from logs or state\n7. Format output in user-friendly markdown format\n\nPseudo-code:\n```\nfunction statusCommand():\n  branch = getGitBranch()\n  tasks = TaskMaster.get_tasks()\n  completed = count(tasks where status == 'done')\n  current = TaskMaster.next_task()\n  iterations = readIterationCount()\n  validation = readLatestValidation()\n  \n  return formatStatus({\n    branch, completed, tasks.length, current, iterations, validation\n  })\n```\n\nOutput format should match the example in PRD with emoji indicators and clear sections.",
        "testStrategy": "Integration tests: (1) Correct git branch retrieved, (2) Task progress calculated correctly, (3) Current task details displayed, (4) Iteration count accurate, (5) Validation results shown, (6) Graceful handling when no execution in progress, (7) Output formatting is readable",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:34:18.467Z"
      },
      {
        "id": "28",
        "title": "Implement /auto-dev:cancel command with user confirmation",
        "description": "Create the cancel command that safely stops the Ralph Loop while preserving work progress. Include user confirmation dialog showing current progress before cancellation.",
        "details": "Create commands/cancel.md with implementation:\n1. Check if execution is currently in progress (state file exists)\n2. Display confirmation dialog with current progress\n3. Get task progress from TaskMaster\n4. Show pending tasks count\n5. Wait for user confirmation (yes/no)\n6. If confirmed:\n   - Delete execution state file\n   - Log cancellation event\n   - Preserve git branch and file changes\n   - Keep TaskMaster task statuses unchanged\n7. If cancelled:\n   - Return to normal execution\n\nPseudo-code:\n```\nfunction cancelCommand():\n  if not isExecutionActive():\n    return \"No active execution\"\n  \n  progress = getTaskProgress()\n  confirmed = showConfirmDialog(progress)\n  \n  if confirmed:\n    deleteStateFile()\n    logEvent('execution_cancelled')\n    return \"Execution cancelled. Work preserved.\"\n  else:\n    return \"Cancellation aborted.\"\n```\n\nConfirmation dialog should show:\n- Current progress (X/Y tasks completed)\n- Number of pending tasks\n- Warning about cancellation\n- Yes/No options",
        "testStrategy": "Integration tests: (1) Detects active execution correctly, (2) Shows confirmation dialog with accurate progress, (3) State file deleted on confirmation, (4) Git changes preserved after cancellation, (5) TaskMaster task statuses unchanged, (6) Graceful handling when no execution active, (7) User can abort cancellation",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:34:46.359Z"
      },
      {
        "id": "29",
        "title": "Create execution state management system",
        "description": "Implement a state management system that tracks execution progress, iteration count, and current task. This supports both status command and cancel command operations.",
        "details": "Create a state management module (e.g., .autodev/state.json or similar):\n1. Define state schema with fields:\n   - execution_active: boolean\n   - start_time: timestamp\n   - current_task_id: number\n   - iteration_count: number\n   - last_validation: object\n   - branch: string\n2. Implement state read/write functions\n3. Initialize state when execute-loop starts\n4. Update iteration count after each loop iteration\n5. Update current task when task changes\n6. Update validation results after verification\n7. Clear state when execution completes or is cancelled\n\nState file location: .autodev/execution-state.json\n\nPseudo-code:\n```\nfunction initializeState(taskId):\n  state = {\n    execution_active: true,\n    start_time: now(),\n    current_task_id: taskId,\n    iteration_count: 0,\n    branch: getGitBranch()\n  }\n  writeStateFile(state)\n\nfunction updateIterationCount():\n  state = readStateFile()\n  state.iteration_count += 1\n  writeStateFile(state)\n```",
        "testStrategy": "Unit tests: (1) State file created correctly, (2) State read/write operations work, (3) Iteration count increments properly, (4) Current task updated correctly, (5) State cleared on completion, (6) Concurrent access handled safely, (7) Corrupted state file handled gracefully",
        "priority": "medium",
        "dependencies": [
          "27",
          "28"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:34:46.361Z"
      },
      {
        "id": "30",
        "title": "Update plugin.json with new commands and skills",
        "description": "Update the plugin.json configuration file to register the new status and cancel commands, and the apply-rules skill. Ensure version is bumped to 0.3.0.",
        "details": "Update plugin.json with the following changes:\n1. Increment version to \"0.3.0\"\n2. Add \"status\" and \"cancel\" to commands array\n3. Add \"apply-rules\" to skills array\n4. Ensure \"taskmaster-ai\" is in mcp_dependencies\n5. Update description to reflect new features\n\nFinal plugin.json structure:\n```json\n{\n  \"name\": \"auto-dev\",\n  \"version\": \"0.3.0\",\n  \"description\": \"自动化开发助手 - 快速迭代，持续学习\",\n  \"commands\": [\"auto-dev\", \"fix\", \"status\", \"cancel\"],\n  \"skills\": [\"execute-loop\", \"learn-from-fix\", \"apply-rules\"],\n  \"mcp_dependencies\": [\"taskmaster-ai\"]\n}\n```\n\nEnsure JSON is valid and properly formatted.",
        "testStrategy": "Validation tests: (1) JSON syntax is valid, (2) All required fields present, (3) Version correctly set to 0.3.0, (4) Commands array includes all four commands, (5) Skills array includes all three skills, (6) Dependencies correctly specified, (7) File is readable by plugin loader",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:35:13.065Z"
      },
      {
        "id": "31",
        "title": "Implement project facts loading from .autodev/project-facts.json",
        "description": "Create functionality to load and parse project facts (tech stack, directory structure, etc.) from the project facts file. This data is used in the execute-prompt template.",
        "details": "Implement project facts loader:\n1. Create function to read .autodev/project-facts.json\n2. Parse JSON and validate structure\n3. Handle missing file gracefully (return default/empty facts)\n4. Format facts for template substitution\n5. Support facts like:\n   - Technology stack (languages, frameworks, libraries)\n   - Directory structure\n   - Key conventions\n   - Testing framework\n   - Build tools\n6. Return formatted string for {{project_facts}} placeholder\n\nPseudo-code:\n```\nfunction loadProjectFacts():\n  try:\n    content = readFile('.autodev/project-facts.json')\n    facts = JSON.parse(content)\n    return formatFactsForTemplate(facts)\n  catch FileNotFound:\n    return ''\n  catch ParseError:\n    log error and return ''\n\nfunction formatFactsForTemplate(facts):\n  lines = []\n  for each key, value in facts:\n    lines.push(`- ${key}: ${value}`)\n  return lines.join('\\n')\n```\n\nExpected project-facts.json structure (from V0.2):\n```json\n{\n  \"tech_stack\": [...],\n  \"directory_structure\": {...},\n  \"conventions\": {...}\n}\n```",
        "testStrategy": "Unit tests: (1) Valid project-facts.json parsed correctly, (2) Missing file returns empty string, (3) Malformed JSON handled gracefully, (4) Facts formatted as readable text, (5) All fact types supported, (6) Special characters escaped properly",
        "priority": "medium",
        "dependencies": [
          "25"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:35:13.066Z"
      },
      {
        "id": "32",
        "title": "Implement validation result tracking and display",
        "description": "Create a system to track and store validation results (test passes/failures) so they can be displayed in the status command. This provides feedback on the latest execution results.",
        "details": "Implement validation tracking:\n1. Create validation log file (.autodev/validation-log.json or similar)\n2. After each task verification, record:\n   - Task ID\n   - Timestamp\n   - Test results (passed/failed count)\n   - Test output summary\n   - Status (success/failure)\n3. Implement function to get latest validation result\n4. Format validation result for status command display\n5. Keep last N validation results (e.g., last 10)\n\nPseudo-code:\n```\nfunction recordValidation(taskId, testResults):\n  validation = {\n    task_id: taskId,\n    timestamp: now(),\n    passed: testResults.passed,\n    failed: testResults.failed,\n    status: testResults.failed == 0 ? 'success' : 'failure'\n  }\n  appendToLog(validation)\n\nfunction getLatestValidation():\n  log = readValidationLog()\n  return log[log.length - 1]\n```\n\nValidation log format:\n```json\n[\n  {\n    \"task_id\": 1,\n    \"timestamp\": \"2024-01-12T10:30:00Z\",\n    \"passed\": 12,\n    \"failed\": 0,\n    \"status\": \"success\"\n  }\n]\n```",
        "testStrategy": "Unit tests: (1) Validation recorded correctly, (2) Latest validation retrieved, (3) Log file created and appended, (4) Old entries preserved, (5) Malformed log handled gracefully, (6) Validation formatted for display",
        "priority": "low",
        "dependencies": [
          "27"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:35:13.067Z"
      },
      {
        "id": "33",
        "title": "Create comprehensive integration tests for V0.3 features",
        "description": "Develop end-to-end integration tests that verify the complete workflow of rule application, status tracking, and cancellation. Tests should cover the interaction between all new components.",
        "details": "Create integration test suite covering:\n1. Full execution flow with rule application:\n   - Load rules from .autodev/rules.md\n   - Match rules to task\n   - Apply rules to execute-prompt\n   - Verify rules appear in final prompt\n\n2. Status command workflow:\n   - Start execution\n   - Call status command\n   - Verify all information displayed correctly\n   - Update task progress\n   - Call status again\n   - Verify progress updated\n\n3. Cancel command workflow:\n   - Start execution\n   - Call cancel command\n   - Confirm cancellation\n   - Verify state file deleted\n   - Verify git changes preserved\n   - Verify TaskMaster state unchanged\n\n4. Template substitution:\n   - All variables substituted correctly\n   - Missing variables handled\n   - Complex values formatted properly\n\n5. Error scenarios:\n   - Missing rules.md\n   - Missing project-facts.json\n   - Corrupted state file\n   - No active execution\n\nTest framework: Jest or similar with mocking for git and file operations.",
        "testStrategy": "Integration tests with mocked dependencies: (1) Mock git operations, (2) Mock file system, (3) Mock TaskMaster API, (4) Verify complete workflows, (5) Test error paths, (6) Verify state consistency, (7) Test concurrent operations",
        "priority": "medium",
        "dependencies": [
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:35:13.068Z"
      },
      {
        "id": "34",
        "title": "Create documentation for V0.3 features",
        "description": "Write comprehensive documentation for the new features including apply-rules skill, status command, cancel command, and the updated execute-loop workflow. Include examples and troubleshooting guides.",
        "details": "Create documentation files:\n1. skills/apply-rules/README.md:\n   - Overview of rule application\n   - How rules are matched\n   - Examples of rule matching\n   - Configuration options\n\n2. commands/status.md:\n   - Command usage and syntax\n   - Output explanation\n   - Example outputs\n   - Troubleshooting\n\n3. commands/cancel.md:\n   - Command usage and syntax\n   - Confirmation dialog explanation\n   - What happens to work in progress\n   - Recovery options\n\n4. WORKFLOW.md:\n   - Updated execute-loop flow with rule application\n   - Template variable explanation\n   - State management overview\n   - Complete example workflow\n\n5. TROUBLESHOOTING.md:\n   - Common issues and solutions\n   - Debug tips\n   - State file inspection\n   - Log file locations\n\nDocumentation should include:\n- Clear explanations\n- Code examples\n- Diagrams where helpful\n- Troubleshooting sections",
        "testStrategy": "Documentation review: (1) All features documented, (2) Examples are accurate, (3) Commands match implementation, (4) No broken links, (5) Markdown formatting correct, (6) Screenshots/diagrams present where needed",
        "priority": "low",
        "dependencies": [
          "22",
          "27",
          "28"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T08:35:13.068Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-13T08:35:13.068Z",
      "taskCount": 13,
      "completedCount": 13,
      "tags": [
        "master"
      ]
    }
  }
}